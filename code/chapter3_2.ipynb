{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c04da39",
   "metadata": {},
   "source": [
    "## Chapter 3: DataFrames\n",
    "\n",
    "A DataFrame is a two-dimensional data structure in which information is organized in rows and columns, much like a table. To use DataFrames, we need to import the [Pandas](https://pandas.pydata.org) library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # import os library to work with directories\n",
    "import pandas as pd # import pandas library under the alias pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af677360",
   "metadata": {},
   "source": [
    "Let’s see one example. Suppose we want to convert the following table into a DataFrame:\n",
    "\n",
    "| mineral | hardness | density |\n",
    "| ------- | -------- | ------- |\n",
    "| halite | 2.5 | 2.17 |\n",
    "| quartz | 7 | 2.65 |\n",
    "| hematite | 6 | 5.3|\n",
    "| rutile | 6 | 4.24 |\n",
    "| olivine | 7 | 3.4 |\n",
    "\n",
    "We can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd97ff95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame() # create an empty DataFrame\n",
    "\n",
    "# add columns to the DataFrame using lists\n",
    "# note that lists/columns should have the same length\n",
    "df[\"mineral\"] = [\"halite\", \"quartz\", \"hematite\", \n",
    "                 \"rutile\", \"olivine\"]\n",
    "df[\"hardness\"] = [2.5, 7, 6, 6, 7]\n",
    "df[\"density\"] = [2.17, 2.65, 5.3, 4.24, 3.4]\n",
    "\n",
    "df.head() # view first 5 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d56aac3",
   "metadata": {},
   "source": [
    "Here, we added columns to the DataFrame using lists. The column on the far left—unlabeled by default—displays the index values, which help identify individualrows. Alternatively, we can create the DataFrame using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554760aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Dictionary\n",
    "my_dict = {\"mineral\":[\"halite\", \"quartz\", \"hematite\", \n",
    "                      \"rutile\", \"olivine\"],\n",
    "          \"hardness\":[2.5, 7, 6, 6, 7], \n",
    "          \"density\":[2.17, 2.65, 5.3, 4.24, 3.4]}\n",
    "\n",
    "# create DataFrame using Dictionary\n",
    "df = pd.DataFrame(my_dict)\n",
    "\n",
    "df.info() # view first 5 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea5d59d",
   "metadata": {},
   "source": [
    "In this case the dictionary keys are the names of the columns, and the values are the entries of the columns. What type of object is a DataFrame column? Let’s see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bf5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df[\"mineral\"]), type(df[\"hardness\"]), type(df[\"density\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68b276",
   "metadata": {},
   "source": [
    "Each column in a DataFrame is a [Series](https://pandas.pydata.org/docs/reference/api/pandas.Series.html). Unlike lists, Series offer greater flexibility and support vectorized operations. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46679d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column of hardness/density\n",
    "df[\"hardness/density\"] = df[\"hardness\"] / df[\"density\"] \n",
    "\n",
    "df.describe() # view first 5 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296800f9",
   "metadata": {},
   "source": [
    "## NCS production data\n",
    "\n",
    "To better illustrate the power of DataFrames, let’s explore a practical example using monthly production data from oil and gas fields on the Norwegian Continental Shelf (NCS). This dataset is published by the Norwegian Offshore Directorate (NOD) and can be accessed [here](https://factpages.sodir.no/en/field/TableView/Production/Saleable/Monthly).\n",
    "\n",
    "Let’s read the data into a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf0f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read field_production_monthly.csv file\n",
    "# which is in the data directory\n",
    "\n",
    "# path to file\n",
    "path = os.path.join(\"..\", \"data\", \"field_production_monthly.csv\")\n",
    "\n",
    "# read csv file into DataFrame\n",
    "df = pd.read_csv(path) \n",
    "\n",
    "df.head() # view first 5 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f25af6",
   "metadata": {},
   "source": [
    "In the cell above, we use Python’s [os](https://docs.python.org/3/library/os.html) library to construct a path to the CSV\n",
    "file. We then load the data using Pandas’ `read_csv()` method, which reads comma-separated values into a DataFrame. Finally, we display the first five rows of the DataFrame using its `head()` method.\n",
    "\n",
    "We can get more information about the DataFrame using its `info()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # view DataFrame information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56ce7ba",
   "metadata": {},
   "source": [
    "The DataFrame has 10 columns and 26,580 entries. The column names are rather long, so for convenience let’s extract them into a list. We can use the DataFrame `columns` attribute to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3767c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names\n",
    "columns = df.columns.tolist() \n",
    "print(columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806bbb8f",
   "metadata": {},
   "source": [
    "Let's filter the DataFrame to include only the fields operated by ConocoPhillips. First, we create a list of the relevant field names. Then, we filter the DataFrame by selecting rows where the first column (`columns[0]`, which contains the field names) matches an entry in our list. This is done using the `isin()` method of a pandas Series. This method returns a Boolean Series, which we use to filter the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498b1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of ConocoPhillips fields\n",
    "fields = [\"EKOFISK\", \"ELDFISK\", \"TOMMELITEN GAMMA\", \n",
    "          \"TOR\", \"VEST EKOFISK\", \"ALBUSKJELL\", \"VALHALL\", \n",
    "          \"HOD\", \"TOMMELITEN A\"]\n",
    "\n",
    "# filter DataFrame to include only ConocoPhillips fields\n",
    "df = df[df[columns[0]].isin(fields)]\n",
    "\n",
    "df.head() # view first 5 rows of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31bf06",
   "metadata": {},
   "source": [
    "We can get the info for the filtered DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de05188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # view DataFrame information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b91ccd",
   "metadata": {},
   "source": [
    "The DataFrame has now only 3,233 entries. Let’s look at the production of Ekofisk. In the cell below, we make a smaller DataFrame for Ekofisk, and use the DataFrame `describe()` method to get a descriptive statistics of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ece276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look at the Ekofisk field\n",
    "df_ekofisk = df[df[columns[0]] == \"EKOFISK\"]\n",
    "\n",
    "df_ekofisk.describe() # describe DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a5c0e",
   "metadata": {},
   "source": [
    "The `describe()` method is quite powerful, it gives us the number of entries (644), the mean and standard deviation (std), minimum and maximum values (min and max), the lower and upper quartiles (25% and 75%), and the median (50%) of the column’s values.\n",
    "\n",
    "To end this example, let’s calculate the oil and water production of Ekofisk in a given year. To do that, we filter the DataFrame to the year of interest, and sum the entries of the oil production (`columns[3]`) and water production (`columns[8]`) columns, using the Series `sum()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb80b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2015 # year of interest\n",
    "\n",
    "# find out the oil and water production of EKOFISK in year\n",
    "df_ekofisk = df_ekofisk[df_ekofisk[columns[1]] == year] \n",
    "\n",
    "# sum montly oil production \n",
    "oil_prod = df_ekofisk[columns[3]].sum()\n",
    "\n",
    "# sum montly water production\n",
    "water_prod = df_ekofisk[columns[8]].sum()\n",
    "\n",
    "print(f\"Ekofisk oil prod. in {year}: {oil_prod:.4f} Mill Sm3\")\n",
    "print(f\"Ekofisk water prod. in {year}: {water_prod:.4f} Mill Sm3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47285f74",
   "metadata": {},
   "source": [
    "I hope this example has given you a glimpse of the power of the Pandas library. We’ll continue using Pandas throughout the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab27f31",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "The file [xeek_train_subset.csv](../data/xeek_train_subset.csv) in the data folder, contains the logs of 12 wells from the Force 2020 Machine Learning lithology competition. This is a subset of the original dataset which is available at Andy McDonald's [Petrophysics Python Series](https://github.com/andymcdgeo/Petrophysics-Python-Series).\n",
    "\n",
    "- Load the file using the Pandas `read_csv()` method. Use the DataFrame `head()` and `info()` methods to learn more about the DataFrame.\n",
    "\n",
    "- Extract the well 16/10-1 from the DataFrame.  Hint: The well names are in column `WELL`.\n",
    "        \n",
    "- The column`FORCE_2020_LITHOFACIES_LITHOLOGY` contains lithology numbers. The significance of these numbers is as follows:\n",
    "\n",
    "    ```\n",
    "    30000: Sandstone, 65030: Sandstone/Shale, 65000: Shale, 80000: Marl, 74000: Dolomite, 70000: Limestone, 70032: Chalk, 88000: Halite, 86000: Anhydrite, 99000: Tuff, 90000: Coal, 93000: Basement\n",
    "    ```\n",
    "        \n",
    "    Using a dictionary (keys are lithology numbers, values are lithology labels), create a new column called `LITH` with the lithology labels. Hint: Use the Series `map()` method and pass to this method the dictionary.\n",
    "        \n",
    "- The DataFrame `groupby()` function is a powerful tool used to split a DataFrame into groups based on one or more columns. Group the well by lithology (column `LITH`).\n",
    "\n",
    "- Use the DataFrame `describe()` method to get a summary of the statistics of the different lithologies in the well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9ec632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Exercise 1 here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793169a7",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "This exercise builds on Exercise 1 and continues working with the well 16/10-1.\n",
    "\n",
    "- Extract the Gamma Ray log of the well (column `GR`) to a NumPy array. Hint: You can use either the Series `values` attribute or the `to_numpy()` method.\n",
    "\n",
    "- Smooth the GR curve with a 5-point moving average. Hint: Use the NumPy `convolve()` method. Pass to this method the GR array and the moving average filter.\n",
    "\n",
    "- Define a threshold (e.g., GR > 75 API) to identify shale-rich intervals.\n",
    "\n",
    "- Extract the depths (column `DEPTH_MD`) that are likely shale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d70785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do Exercise 2 here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
